\section{Estimating a sum}

In order to use the bound \eqref{x-init} for very large values of $N$, the following estimate will be used.

\begin{lemma}\label{largen}
Let $N \geq N_0 \geq 1$ be natural numbers, and let $\sigma,t > 0$ be such that
$$ \sigma > \frac{t}{2} \log N.$$
Then
$$ \sum_{n=1}^N \frac{b_n^t}{n^\sigma} \leq \sum_{n=1}^{N_0}
\frac{b_n^t}{n^\sigma}  + 
\max( N_0^{1-\sigma} b_{N_0}^t, N^{1-\sigma} b_N^t ) \log \frac{N}{N_0}.$$
\end{lemma}

\begin{proof}  From the identity
$$ \frac{b_n^t}{n^\sigma} = \frac{\exp\left( \frac{t}{4} (\log N - \log n)^2 - \frac{t}{4} (\log N)^2\right) }{n^{\sigma - \frac{t}{2} \log N}}$$
we see that the summands $\frac{b_n^t}{n^\sigma}$ are decreasing for $1 \leq n \leq N$, hence by the integral test one has
\begin{equation}\label{rado}
 \sum_{n=1}^N \frac{b_n^t}{n^\sigma} \leq \sum_{n=1}^{N_0}
\frac{b_n^t}{n^\sigma}  + \int_{N_0}^N \frac{b_a^t}{a^\sigma}\ da.
\end{equation}
Making the change of variables $a = e^u$, the right-hand side becomes
$$\sum_{n=1}^{N_0} \frac{b_n^t}{n^\sigma} \exp( (1-\sigma) u + \frac{t}{4} u^2 )\ du.$$
The expression $(1-\sigma) u + \frac{t}{4} u^2$ is convex in $u$, and is thus bounded by the maximum of its values at the endpoints $u = \log N_0, \log N$; thus
$$\exp( (1-\sigma) u + \frac{t}{4} u^2) \leq N_0^{1-\sigma} b_{N_0}^t, N^{1-\sigma} b_N^t.$$
The claim follows. 
\end{proof}

\begin{remark}  The right-hand side of \eqref{rado} can be evaluated exactly as
$$
\sum_{n=1}^{N_0}
\frac{b_n^t}{n^\sigma}  + \frac{\sqrt \pi}{\sqrt t} \exp(\frac{-(\sigma - 1)^2}{t}) \left( \operatorname{erfi}\left(\frac{\frac{t}{2} \log N  - \sigma + 1}{\sqrt t} \right) - \operatorname{erfi}\left(\frac{\frac{t}{2} \log N_0  - \sigma + 1}{\sqrt t}\right) \right).$$

In practice, this upper bound for $\sum_{n=1}^N \frac{b_n^t}{n^\sigma}$ is slightly more accurate than the one in Lemma \ref{largen}, and is a good approximation even for relatively small values of $N_0$ (e.g., $N_0=100$).  However, the cruder bound above suffices for the numerical values of parameters needed to establish the bound $\Lambda \leq 0.22$.
\end{remark}

\subsection{Fast evaluation of multiple values of $f_t(s)$}

Fix $t \geq 0$.  For the verification of the barrier criterion (Theorem \ref{ubc-0}(iii)) using Corollary \ref{zero-test}, we will need to evaluate the quantity $f_t(s)$ to reasonable accuracy for a large number of values of $s$ in the vicinity of a fixed complex number $X+iy$.  From \eqref{ft-def} we have
\begin{equation}\label{fts}
f_t(s) = \sum_{n=1}^N \frac{n^b b_n^t}{n^{\frac{1+y-iX}{2}}} + \gamma(s) \sum_{n=1}^N \frac{n^a b_n^t}{n^{\frac{1-y+iX}{2}}},
\end{equation}
where $b_n^t$ is given by \eqref{bn-def}, $\gamma(s)$ is given by \eqref{lambda-def}, $N$ is given by \eqref{N-def-main} and
$$ b = b(s) \coloneqq  \frac{1+y-iX}{2} - s_* $$
and
$$ a = a(s) \coloneqq  \frac{1-y-iX}{2} - \overline{s_*} - \kappa$$
with $s_*, \kappa$ defined by \eqref{sn-def}, \eqref{kappa-def}.  In practice the exponents $a,b$ will be rather small, and $N$ will be fixed (in our main verification we will in fact have $N = 69098$).

A naive computation of $f_t(s)$ for $M$ values of $s$ would take time $O(NM)$, which turns out to be numerically infeasible for the ranges of $N,M$ we will need {\bf do we have a value of $M$?  also $t$ varies}.  However, we were able to speed up this calculation by an acceptable amount by subdividing the summation range $\sum_{n=1}^N$ into short intervals of a given length $H$ (we eventually took $H=10$), and then performing a Taylor expansion in each short sum to factor those sums as a linear combination of further sums that do not depend on the parameters $s,a,b$.  These latter sums can be stored in advance, leading to a computational saving.

We turn to the details.  Let $H$ be a small even number, say $H=10$.  We assume that $N$ is a multiple of $H$; if this is not the case, then one can approximate the sums $\sum_{n=1}^N$ in \eqref{fts} by $\sum_{n=1}^{H \lfloor N/H \rfloor}$ and compute the tail $\sum_{n=H\lfloor N/H \rfloor+1}^N$ separately (the latter only requiring time $O(HM)$).  Once $N$ is a multiple of $H$, we can then subdivide
$$ \sum_{n=1}^N F(n) = \sum_{v=1}^{N/H} \sum_{h=-H/2+1}^{H/2} F(n_0(v) + h)$$
for any function $F$, where 
$$ n_0(v) \coloneqq \frac{H}{2} + (v-1) H.$$
We thus have
$$ f_t(s) = \sum_{v=1}^{N/H} B(n_0(v),b) + \gamma(s) \sum_{v=1}^{N/H} A(n_0(v),a)$$
where
$$ B(n_0,b) \coloneqq \sum_{h = -H/2+1}^{H/2} \frac{(n_0+h)^b b_{n_0+h}^t}{(n_0+h)^{\frac{1+y-iX}{2}}}$$
and
$$ A(n_0,a) \coloneqq \sum_{h = -H/2+1}^{H/2} \frac{(n_0+h)^a b_{n_0+h}^t}{(n_0+h)^{\frac{1-y+iX}{2}}}.$$
We discuss the fast computation of $B(n_0,b)$ for multiple values of $b$; the discussion for $A(n_0,a)$ is analogous.  We can write the numerator $(n_0+h)^b b_{n_0+h}^t$ as
$$ \exp( b \log(n_0+h) + \frac{t}{4} \log^2(n_0+h) );$$
writing $\log(n_0+h) = \log n_0 + \log(1+\frac{h}{n_0})$, this becomes
$$ n_0^{b + \frac{t}{4} \log n_0} \exp( \frac{t}{4} \log^2(1+\frac{h}{n_0}) ) \exp( (b + \frac{t}{2} \log n_0) \log(1+\frac{h}{n_0}) ).$$
By Taylor expanding\footnote{We also experimented with Taylor expanding the first exponential, but found that this did not lead to significant numerical speedups.} the second exponential, we can write this as
$$ n_0^{b + \frac{t}{4} \log n_0} \sum_{i=0}^\infty \exp( \frac{t}{4} \log^2(1+\frac{h}{n_0}) ) \log^i(1+\frac{h}{n_0}) \frac{(b+\frac{t}{2} \log n_0)^i}{i!}$$
and thus the expression $B(n_0,b)$ can be written as
$$ B(n_0,b) = n_0^{b + \frac{t}{4} \log n_0} \sum_{i=0}^\infty B_i(n_0) \frac{(b+\frac{t}{2} \log n_0)^i}{i!}$$
where
$$ B_i(n_0) \coloneqq \sum_{h = -H/2+1}^{H/2} \frac{\exp( \frac{t}{4} \log^2(1+\frac{h}{n_0}) ) \log^i(1+\frac{h}{n_0})}{(n_0+h)^{\frac{1+y-iX}{2}}}.$$
If we truncate the $i$ summation at some cutoff $E$, we obtain the approximation
$$ B(n_0,b) \approx n_0^{b + \frac{t}{4} \log n_0} \sum_{i=0}^{E-1} B_i(n_0) \frac{(b+\frac{t}{2} \log n_0)^i}{i!}.$$
For each value of $n_0$, the quantities $B_i(n_0), i=0,\dots,{E-1}$ may be evaluated in time $O(HE)$, and then the sums $B(n_0,b)$ for $M$ values of $b$ may be evaluated in time $O(ME)$.  Summing over the $N/H$ values of $n_0$, and treating the $A(n_0,a)$ terms similarly, we then obtain an approximation to the $M$ values of $f_t(s)$ in time $O( NE + \frac{E}{H} NM )$.  In practice we found that setting $H=10$ and $E=4$ leads to an acceptable speedup.

Of course, to be completely rigorous we also need to estimate the error caused by the cutoff in $i$.

...







